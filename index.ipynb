{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048e39db",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**Sentiment:** When someone feels good about something, it's called a positive feeling, and when they feel bad about something, it's called a negative feeling, those feelings are \"sentiment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607bdadb",
   "metadata": {},
   "source": [
    "# OSEMN\n",
    "* Obtain\n",
    "* Scrub\n",
    "* Explore \n",
    "* Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd08c3",
   "metadata": {},
   "source": [
    "## 1. Obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c87d28",
   "metadata": {},
   "source": [
    "The Twitter Sentiment Analysis Dataset is a corpus of 1,578,627 classified tweets, with each tweet marked as 1 for positive sentiment and 0 for negative sentiment. The dataset is based on data from the University of Michigan Sentiment Analysis competition on Kaggle and the Twitter Sentiment Corpus by Niek Sanders. It is recommended to use 1/10 of the dataset for testing and the rest for training. The dataset has been used to achieve a 75% accuracy rate with a simple Naive Bayesian classification algorithm. The use of natural language processing can be helpful in extracting context and identifying features that contribute towards sentiment deduction. However, it is important to note that social informal communication, such as tweets, may not conform to grammatical rules and contain shortened words and overuse of punctuation. Despite these limitations, the dataset provides a good starting point for sentiment analysis modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635209e",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328324f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment SentimentSource  \\\n",
       "ItemID                              \n",
       "1               0    Sentiment140   \n",
       "2               0    Sentiment140   \n",
       "3               1    Sentiment140   \n",
       "4               0    Sentiment140   \n",
       "5               0    Sentiment140   \n",
       "6               0    Sentiment140   \n",
       "7               1    Sentiment140   \n",
       "\n",
       "                                            SentimentText  \n",
       "ItemID                                                     \n",
       "1                            is so sad for my APL frie...  \n",
       "2                          I missed the New Moon trail...  \n",
       "3                                 omg its already 7:30 :O  \n",
       "4                 .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "5                i think mi bf is cheating on me!!!   ...  \n",
       "6                       or i just worry too much?          \n",
       "7                      Juuuuuuuuuuuuuuuuussssst Chillin!!  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "\n",
    "# read the csv file to table\n",
    "df = pd.read_csv(\"/home/munyao/Desktop/flat_iron_school/Moringa/phase_4/NLP/Data/Sentiment Analysis Dataset.csv\", on_bad_lines='skip', index_col=0)\n",
    "\n",
    "# preview first 7 rows of dataset.\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574dddf",
   "metadata": {},
   "source": [
    "## Scrub\n",
    "* Removing stop words (words that are very common and do not add much meaning to the text)\n",
    "* Removing punctuation and special characters\n",
    "* Tokenizing the text (splitting it into words or phrases)\n",
    "* Stemming or lemmatizing the words (reducing them to their base form)\n",
    "* Removing URLs, mentions, or hashtags if you are working with social media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1560308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578623</th>\n",
       "      <td>Zzzzzz.... Finally! Night tweeters!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578624</th>\n",
       "      <td>Zzzzzzz, sleep well people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578625</th>\n",
       "      <td>ZzzZzZzzzZ... wait no I have homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578626</th>\n",
       "      <td>ZzZzzzZZZZzzz meh, what am I doing up again?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578627</th>\n",
       "      <td>Zzzzzzzzzzzzzzzzzzz, I wish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578612 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SentimentText\n",
       "ItemID                                                    \n",
       "1                             is so sad for my APL frie...\n",
       "2                           I missed the New Moon trail...\n",
       "3                                  omg its already 7:30 :O\n",
       "4                  .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "5                 i think mi bf is cheating on me!!!   ...\n",
       "...                                                    ...\n",
       "1578623               Zzzzzz.... Finally! Night tweeters! \n",
       "1578624                        Zzzzzzz, sleep well people \n",
       "1578625            ZzzZzZzzzZ... wait no I have homework. \n",
       "1578626      ZzZzzzZZZZzzz meh, what am I doing up again? \n",
       "1578627                       Zzzzzzzzzzzzzzzzzzz, I wish \n",
       "\n",
       "[1578612 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"SentimentText\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361dec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment          0\n",
       "SentimentSource    0\n",
       "SentimentText      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531042c",
   "metadata": {},
   "source": [
    "### Text Preprocessing.\n",
    ">A function in python using the Natural Language Toolkit (NLTK) library to perform the text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e46e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# download the stopwords and lemmatizer data\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# define the pre-processing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove URLs, mentions, and hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+|@[^\\s]+|#\\S+', '', text)\n",
    "\n",
    "    # remove punctuation and special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # tokenize the text into words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # perform lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # join the tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# apply pre-processing to the 'text' column\n",
    "df['ProcessedSentimentText'] = df['SentimentText'].apply(preprocess_text)\n",
    "\n",
    "# show the processed DataFrame\n",
    "df.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3127a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>ProcessedSentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>missed new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg already 730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga im sooo im gunna cry ive dentist since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>think mi bf cheating tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578623</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzzzz.... Finally! Night tweeters!</td>\n",
       "      <td>zzzzzz finally night tweeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578624</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzzzzz, sleep well people</td>\n",
       "      <td>zzzzzzz sleep well people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578625</th>\n",
       "      <td>0</td>\n",
       "      <td>ZzzZzZzzzZ... wait no I have homework.</td>\n",
       "      <td>zzzzzzzzzz wait homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578626</th>\n",
       "      <td>0</td>\n",
       "      <td>ZzZzzzZZZZzzz meh, what am I doing up again?</td>\n",
       "      <td>zzzzzzzzzzzzz meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578627</th>\n",
       "      <td>0</td>\n",
       "      <td>Zzzzzzzzzzzzzzzzzzz, I wish</td>\n",
       "      <td>zzzzzzzzzzzzzzzzzzz wish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                      SentimentText  \\\n",
       "ItemID                                                                  \n",
       "1                0                       is so sad for my APL frie...   \n",
       "2                0                     I missed the New Moon trail...   \n",
       "3                1                            omg its already 7:30 :O   \n",
       "4                0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "5                0           i think mi bf is cheating on me!!!   ...   \n",
       "...            ...                                                ...   \n",
       "1578623          1               Zzzzzz.... Finally! Night tweeters!    \n",
       "1578624          1                        Zzzzzzz, sleep well people    \n",
       "1578625          0            ZzzZzZzzzZ... wait no I have homework.    \n",
       "1578626          0      ZzZzzzZZZZzzz meh, what am I doing up again?    \n",
       "1578627          0                       Zzzzzzzzzzzzzzzzzzz, I wish    \n",
       "\n",
       "                                    ProcessedSentimentText  \n",
       "ItemID                                                      \n",
       "1                                           sad apl friend  \n",
       "2                                  missed new moon trailer  \n",
       "3                                          omg already 730  \n",
       "4        omgaga im sooo im gunna cry ive dentist since ...  \n",
       "5                                  think mi bf cheating tt  \n",
       "...                                                    ...  \n",
       "1578623                       zzzzzz finally night tweeter  \n",
       "1578624                          zzzzzzz sleep well people  \n",
       "1578625                           zzzzzzzzzz wait homework  \n",
       "1578626                                  zzzzzzzzzzzzz meh  \n",
       "1578627                           zzzzzzzzzzzzzzzzzzz wish  \n",
       "\n",
       "[1578612 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the sentimentsource column\n",
    "processed_df = df.drop([\"SentimentSource\"], axis=1)\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7beaa",
   "metadata": {},
   "source": [
    "## vectorization\n",
    "convert the preprocessed text data into a numerical representation using BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61e8e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df[['ProcessedSentimentText']]\n",
    "# create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "y = df[['Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e9daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the pre-processed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['ProcessedSentimentText']], df[['Sentiment']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5d9e3a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1578612]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# train a logistic regression model on the training data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 1578612]"
     ]
    }
   ],
   "source": [
    "# import relevant libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a logistic regression model on the training data\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b75e6e",
   "metadata": {},
   "source": [
    "I analyze the text data using a tool called the Fourier transform. This tool helps us understand the different patterns and frequencies in the text. I use this information to figure out how people feel in the text. For example, we might find that certain patterns are associated with happy or sad feelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5de8ab95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sad apl friend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m text_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(processed_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessedSentimentText\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the DFT to the text data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dft \u001b[38;5;241m=\u001b[39m \u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the power spectrum of the DFT\u001b[39;00m\n\u001b[1;32m     12\u001b[0m power_spectrum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(dft) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/scipy/fft/_backend.py:25\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/scipy/fft/_pocketfft/basic.py:17\u001b[0m, in \u001b[0;36mc2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plan \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassing a precomputed plan is not yet \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported by scipy.fft functions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43m_asfarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m overwrite_x \u001b[38;5;241m=\u001b[39m overwrite_x \u001b[38;5;129;01mor\u001b[39;00m _datacopied(tmp, x)\n\u001b[1;32m     19\u001b[0m norm \u001b[38;5;241m=\u001b[39m _normalization(norm, forward)\n",
      "File \u001b[0;32m~/anaconda3/envs/sentiment_env/lib/python3.10/site-packages/scipy/fft/_pocketfft/helper.py:92\u001b[0m, in \u001b[0;36m_asfarray\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(x, np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Require native byte order\u001b[39;00m\n\u001b[1;32m     95\u001b[0m dtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'sad apl friend'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Convert the SentimentText column to a numpy array\n",
    "text_data = np.array(processed_df['ProcessedSentimentText'])\n",
    "\n",
    "# Apply the DFT to the text data\n",
    "dft = fft(text_data)\n",
    "\n",
    "# Calculate the power spectrum of the DFT\n",
    "power_spectrum = np.abs(dft) ** 2\n",
    "\n",
    "# Plot the power spectrum\n",
    "freq = np.fft.fftfreq(len(power_spectrum))\n",
    "plt.plot(freq, power_spectrum)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power')\n",
    "plt.title('Power Spectrum of SentimentText Before Processing')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "\n",
    "# apply Fourier transform to the BOW representation\n",
    "fft_representation = fft(bow_sparse_matrix)\n",
    "\n",
    "# print the resulting Fourier coefficients\n",
    "print(fft_representation.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(freqs[np.argmax(X_freq, axis=1)], bins=20) # plot most prominent frequency for each document\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "sentiment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
